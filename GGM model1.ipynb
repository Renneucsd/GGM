{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.datasets import make_regression\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=400\n",
    "d=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.2 0.2 ... 0.  0.  0. ]\n",
      " [0.2 1.  0.2 ... 0.  0.  0. ]\n",
      " [0.2 0.2 1.  ... 0.  0.  0. ]\n",
      " ...\n",
      " [0.  0.  0.  ... 1.  0.2 0.2]\n",
      " [0.  0.  0.  ... 0.2 1.  0.2]\n",
      " [0.  0.  0.  ... 0.2 0.2 1. ]]\n"
     ]
    }
   ],
   "source": [
    "mu=np.zeros(d)\n",
    "sigma=np.zeros((d,d))\n",
    "sigma[0,1]=0.2\n",
    "sigma[0,2]=0.2\n",
    "sigma[1,0]=0.2\n",
    "sigma[1,2]=0.2\n",
    "sigma[1,3]=0.2\n",
    "sigma[d-1,d-2]=0.2\n",
    "sigma[d-1,d-3]=0.2\n",
    "sigma[d-2,d-1]=0.2\n",
    "sigma[d-2,d-3]=0.2\n",
    "sigma[d-2,d-4]=0.2\n",
    "for i in range (sigma.shape[0]):\n",
    "     sigma[i,i]=1\n",
    "for i in range(2,d-2):\n",
    "    sigma[i,i-2]=0.2\n",
    "    sigma[i,i-1]=0.2\n",
    "    sigma[i,i+1]=0.2\n",
    "    sigma[i,i+2]=0.2\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0779310139207985\n"
     ]
    }
   ],
   "source": [
    "W=np.linalg.inv(sigma)\n",
    "print(W[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCAD_dev1(t,a,Self_lamda):\n",
    "    if (t<=Self_lamda ) :\n",
    "        dev=Self_lamda \n",
    "    else: \n",
    "        dev=max(a*Self_lamda-t,0)/(a-1)\n",
    "    return(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCAD_dev2 (intheta,X,Y,n,d,lamda):\n",
    "    dev=torch.zeros(d,1).to(device) \n",
    "    for i in range(dev.shape[0]):\n",
    "        t=abs(intheta[i,:])\n",
    "        dev[i,:]=SCAD_dev1(t,3,lamda)\n",
    "        dev[0,0]=0\n",
    "    return(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft(input_theta,X,Y,n,d,sk,dev):\n",
    "    A2=Y-X.mm(input_theta)\n",
    "    A1=torch.t(X).mm(A2)\n",
    "    a=sk/n\n",
    "    A=input_theta+A1.mul(a)  \n",
    "    zero1=torch.zeros(d,1).to(device)\n",
    "    B=torch.abs(A)-dev.mul(sk)\n",
    "    C=torch.max(B,zero1)\n",
    "    D=torch.sign(A)\n",
    "    output=D.mul(C)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(input,X,Y,n,d,sk,dev):\n",
    "    new=soft(input,X,Y,n,d,sk,dev)\n",
    "    di=new-input\n",
    "    epi_new=Y-X.mm(new)\n",
    "    epi=Y-X.mm(input)\n",
    "    ##\n",
    "    Q=torch.t(epi_new).mm(epi_new.div(2*n))\n",
    "    ##\n",
    "    A=torch.t(epi).mm(epi.div(2*n))\n",
    "    B1=-torch.t(X).mm(epi) \n",
    "    B=torch.t(di).mm(B1)\n",
    "    C=torch.t(di).mm(di)/(2*(sk))\n",
    "    dif=A+B+C-Q\n",
    "    return(dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_s (input,X,Y,n,d,dev):\n",
    "    k=1\n",
    "    dd=diff(input,X,Y,n,d,k,dev)\n",
    "    while dd<0 :\n",
    "        k=k*(0.1)\n",
    "        dd=diff(input,X,Y,n,d,k,dev)\n",
    "    return(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ISTA (input,X,Y,n,d,dev):\n",
    "    sk=0.075\n",
    "    output=soft(input,X,Y,n,d,sk,dev)\n",
    "    while torch.max(torch.abs(input-output))>1e-5:\n",
    "        sk=choose_s(input,X,Y,n,d,dev)\n",
    "        input=output\n",
    "        output=soft(input,X,Y,n,d,sk,dev)\n",
    "    return(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLA (X,Y,lamda,n,d):\n",
    "    intheta=torch.zeros(d,1).to(device)\n",
    "    dev = SCAD_dev2(intheta,X,Y,n,d,lamda)\n",
    "    outtheta= ISTA(intheta,X,Y,n,d,dev)\n",
    "    while torch.max(torch.abs(intheta-outtheta))>1e-5:\n",
    "        intheta=outtheta\n",
    "        outtheta=ISTA(intheta,X,Y,n,d,dev)\n",
    "        dev=SCAD_dev2(intheta,X,Y,n,d,lamda)\n",
    "    return(outtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCAD(X_cuda,Y_cuda,lamda,n,d):\n",
    "#     start = datetime.datetime.now()\n",
    "    theta_scad = LLA(X_cuda,Y_cuda,lamda,n,d)\n",
    "#     end = datetime.datetime.now()\n",
    "#     print(end-start)\n",
    "    return(theta_scad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X_cuda,Y_cuda,lamda):\n",
    "    list1=list(range(0, 80))\n",
    "    list2=list(range(80, 160))\n",
    "    list3=list(range(160, 240))\n",
    "    list4=list(range(240, 320))\n",
    "    list5=list(range(320, 400))\n",
    "#############################\n",
    "    indicex1 = torch.LongTensor(list1).to(device)\n",
    "    indiceX1 = torch.LongTensor(list2+list3+list4+list5).to(device)\n",
    "    X1=torch.index_select(X_cuda, 0, indiceX1).to(device)\n",
    "    x1=torch.index_select(X_cuda, 0, indicex1).to(device)\n",
    "    Y1=torch.index_select(Y_cuda, 0, indiceX1).to(device)\n",
    "    y1=torch.index_select(Y_cuda, 0, indicex1).to(device)\n",
    "    t1= SCAD(X1,Y1,lamda,320,500)\n",
    "    epi1=y1-x1.mm(t1)\n",
    "    w1=torch.t(epi1).mm(epi1)\n",
    "###############################    \n",
    "    indicex2 = torch.LongTensor(list2).to(device)\n",
    "    indiceX2 = torch.LongTensor(list1+list3+list4+list5).to(device)\n",
    "    X2=torch.index_select(X_cuda, 0, indiceX2).to(device)\n",
    "    x2=torch.index_select(X_cuda, 0, indicex2).to(device)\n",
    "    Y2=torch.index_select(Y_cuda, 0, indiceX2).to(device)\n",
    "    y2=torch.index_select(Y_cuda, 0, indicex2).to(device)\n",
    "    t2= SCAD(X2,Y2,lamda,320,500)\n",
    "    epi2=y2-x2.mm(t2)\n",
    "    w2=torch.t(epi2).mm(epi2)\n",
    "############################ \n",
    "    indicex3 = torch.LongTensor(list3).to(device)\n",
    "    indiceX3 = torch.LongTensor(list2+list1+list4+list5).to(device)\n",
    "    X3=torch.index_select(X_cuda, 0, indiceX3).to(device)\n",
    "    x3=torch.index_select(X_cuda, 0, indicex3).to(device)\n",
    "    Y3=torch.index_select(Y_cuda, 0, indiceX3).to(device)\n",
    "    y3=torch.index_select(Y_cuda, 0, indicex3).to(device)\n",
    "    t3= SCAD(X3,Y3,lamda,320,500)\n",
    "    epi3=y3-x3.mm(t3)\n",
    "    w3=torch.t(epi3).mm(epi3)\n",
    "#################################\n",
    "    indicex4 = torch.LongTensor(list4).to(device)\n",
    "    indiceX4 = torch.LongTensor(list2+list3+list1+list5).to(device)\n",
    "    X4=torch.index_select(X_cuda, 0, indiceX4).to(device)\n",
    "    x4=torch.index_select(X_cuda, 0, indicex4).to(device)\n",
    "    Y4=torch.index_select(Y_cuda, 0, indiceX4).to(device)\n",
    "    y4=torch.index_select(Y_cuda, 0, indicex4).to(device)\n",
    "    t4= SCAD(X4,Y4,lamda,320,500)\n",
    "    epi4=y4-x4.mm(t4)\n",
    "    w4=torch.t(epi4).mm(epi4)\n",
    "################################\n",
    "    indicex5 = torch.LongTensor(list5).to(device)\n",
    "    indiceX5 = torch.LongTensor(list2+list3+list4+list1).to(device)\n",
    "    X5=torch.index_select(X_cuda, 0, indiceX5).to(device)\n",
    "    x5=torch.index_select(X_cuda, 0, indicex5).to(device)\n",
    "    Y5=torch.index_select(Y_cuda, 0, indiceX5).to(device)\n",
    "    y5=torch.index_select(Y_cuda, 0, indicex5).to(device)\n",
    "    t5= SCAD(X5,Y5,lamda,320,500)\n",
    "    epi5=y5-x5.mm(t5)\n",
    "    w5=torch.t(epi5).mm(epi5)\n",
    "##################################\n",
    "    error=(w1+w2+w3+w4+w5)/400\n",
    "    print(error)\n",
    "    return(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sup(beta1):\n",
    "    b=torch.zeros(500,1).to(device)\n",
    "    b[beta1!=0]=1\n",
    "    s=torch.sum(b)\n",
    "    return(s-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.multivariate_normal(mu, W, n)\n",
    "X_np=sample.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:08.598302\n",
      "11\n",
      "0.6774772487670018\n"
     ]
    }
   ],
   "source": [
    "i=55\n",
    "X_copy=X_np\n",
    "Xj_np=np.zeros((1,400))\n",
    "Xj_np[0,:]=X_copy[i,:]\n",
    "X_j_np=np.delete(X_copy,[i],axis=0)\n",
    "X_j_np.shape\n",
    "#############################\n",
    "Xj1=Xj_np.astype(\"float32\")\n",
    "Xj2=torch.from_numpy(Xj1).to(device)\n",
    "Xj=torch.t(Xj2)\n",
    "X_j1=X_j_np.astype(\"float32\")\n",
    "X_j2=torch.from_numpy(X_j1).to(device)\n",
    "X_j=torch.t(X_j2)\n",
    "one=torch.ones(400,1).to(device)\n",
    "X_j_sum=torch.cat((one,X_j),1)\n",
    "#####################\n",
    "beta1=SCAD(X_j_sum,Xj,0.11,400,500)\n",
    "supp=int(sup(beta1))\n",
    "print(supp)\n",
    "#########################\n",
    "XX=X_j_sum.cpu().detach().numpy()\n",
    "YY=Xj.cpu().detach().numpy()\n",
    "Y=np.squeeze(YY)\n",
    "##############################\n",
    "reg = OrthogonalMatchingPursuit(supp).fit(XX, Y)\n",
    "p=reg.coef_\n",
    "###############################\n",
    "Z=Y-XX.dot(p)\n",
    "r=Z.T.dot(Z)/(n-supp)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:15.593819\n"
     ]
    }
   ],
   "source": [
    "beta1=SCAD(X_j_sum,Xj,0.08,400,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:08.275410\n",
      "0:00:08.346538\n",
      "0:00:07.416819\n",
      "0:00:12.235783\n",
      "0:00:05.459773\n",
      "tensor([[0.8296]], device='cuda:0')\n",
      "0:00:16.802422\n",
      "0:00:07.758412\n",
      "0:00:12.983783\n",
      "0:00:06.920286\n",
      "0:00:14.444017\n",
      "tensor([[0.8203]], device='cuda:0')\n",
      "0:00:09.363555\n",
      "0:00:12.407128\n",
      "0:00:08.671890\n",
      "0:00:09.082471\n",
      "0:00:12.526433\n",
      "tensor([[0.8164]], device='cuda:0')\n",
      "0:00:07.430913\n",
      "0:00:10.746168\n",
      "0:00:03.101345\n",
      "0:00:07.893238\n",
      "0:00:09.955327\n",
      "tensor([[0.8148]], device='cuda:0')\n",
      "0:00:04.793332\n",
      "0:00:04.928004\n",
      "0:00:03.884821\n",
      "0:00:04.627703\n",
      "0:00:04.742211\n",
      "tensor([[0.8166]], device='cuda:0')\n",
      "0:00:04.682214\n",
      "0:00:04.762705\n",
      "0:00:03.983932\n",
      "0:00:03.978144\n",
      "0:00:04.610135\n",
      "tensor([[0.8211]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for s in range(0,6):\n",
    "    cross_validation(X_j_sum,Xj,0.08+0.01*s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.14521931]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.25610759]\n",
      " [ 1.11400813]\n",
      " [ 0.        ]\n",
      " [ 0.29963901]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.14401425]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.13303459]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w=p/r\n",
    "w[0]=1/r\n",
    "read=np.zeros((500,1))\n",
    "for k in range(0,i):\n",
    "    read[k]=w[k+1]\n",
    "read[i]=w[0]\n",
    "for k in range(i+1,500):\n",
    "    read[k]=w[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega=np.zeros((500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 0 0:00:09.787189\n",
      "loop 1 0:00:06.810390\n",
      "loop 2 0:00:12.547409\n",
      "loop 3 0:00:07.448789\n",
      "loop 4 0:00:11.167550\n",
      "loop 5 0:00:06.044198\n",
      "loop 6 0:00:07.183950\n",
      "loop 7 0:00:06.539008\n",
      "loop 8 0:00:07.059090\n",
      "loop 9 0:00:09.128021\n",
      "loop 10 0:00:06.333153\n",
      "loop 11 0:00:14.962745\n",
      "loop 12 0:00:15.825703\n",
      "loop 13 0:00:15.299428\n",
      "loop 14 0:00:07.109426\n",
      "loop 15 0:00:15.528561\n",
      "loop 16 0:00:14.641215\n",
      "loop 17 0:00:20.163246\n",
      "loop 18 0:00:10.317571\n",
      "loop 19 0:00:13.374308\n",
      "loop 20 0:00:06.275580\n",
      "loop 21 0:00:10.428648\n",
      "loop 22 0:00:09.839278\n",
      "loop 23 0:00:11.066331\n",
      "loop 24 0:00:06.762952\n",
      "loop 25 0:00:09.729359\n",
      "loop 26 0:00:11.452223\n",
      "loop 27 0:00:06.597580\n",
      "loop 28 0:00:13.180830\n",
      "loop 29 0:00:13.506180\n",
      "loop 30 0:00:06.879544\n",
      "loop 31 0:00:10.464332\n",
      "loop 32 0:00:12.386370\n",
      "loop 33 0:00:10.185355\n",
      "loop 34 0:00:05.097648\n",
      "loop 35 0:00:06.522935\n",
      "loop 36 0:00:06.392925\n",
      "loop 37 0:00:07.404895\n",
      "loop 38 0:00:10.488762\n",
      "loop 39 0:00:06.933456\n",
      "loop 40 0:00:12.101444\n",
      "loop 41 0:00:06.780287\n",
      "loop 42 0:00:08.474389\n",
      "loop 43 0:00:06.420440\n",
      "loop 44 0:00:07.857004\n",
      "loop 45 0:00:10.332115\n",
      "loop 46 0:00:11.182355\n",
      "loop 47 0:00:08.105153\n",
      "loop 48 0:00:09.436157\n",
      "loop 49 0:00:12.100382\n",
      "loop 50 0:00:06.444773\n",
      "loop 51 0:00:06.622998\n",
      "loop 52 0:00:06.411756\n",
      "loop 53 0:00:06.710199\n",
      "loop 54 0:00:08.414299\n",
      "loop 55 0:00:15.084111\n",
      "loop 56 0:00:10.342839\n",
      "loop 57 0:00:14.972237\n",
      "loop 58 0:00:07.165656\n",
      "loop 59 0:00:10.343561\n",
      "loop 60 0:00:09.402991\n",
      "loop 61 0:00:07.587142\n",
      "loop 62 0:00:13.853022\n",
      "loop 63 0:00:14.040361\n",
      "loop 64 0:00:08.419620\n",
      "loop 65 0:00:10.378565\n",
      "loop 66 0:00:09.782683\n",
      "loop 67 0:00:05.424034\n",
      "loop 68 0:00:08.101603\n",
      "loop 69 0:00:06.285820\n",
      "loop 70 0:00:11.017205\n",
      "loop 71 0:00:06.718079\n",
      "loop 72 0:00:11.189641\n",
      "loop 73 0:00:06.249819\n",
      "loop 74 0:00:08.620024\n",
      "loop 75 0:00:05.989724\n",
      "loop 76 0:00:07.613464\n",
      "loop 77 0:00:05.682805\n",
      "loop 78 0:00:06.476563\n",
      "loop 79 0:00:06.720800\n",
      "loop 80 0:00:06.308380\n",
      "loop 81 0:00:12.612903\n",
      "loop 82 0:00:11.527272\n",
      "loop 83 0:00:11.511050\n",
      "loop 84 0:00:10.236245\n",
      "loop 85 0:00:10.912704\n",
      "loop 86 0:00:12.409238\n",
      "loop 87 0:00:13.986451\n",
      "loop 88 0:00:13.198716\n",
      "loop 89 0:00:12.440738\n",
      "loop 90 0:00:06.345188\n",
      "loop 91 0:00:09.445872\n",
      "loop 92 0:00:11.138997\n",
      "loop 93 0:00:10.129063\n",
      "loop 94 0:00:07.235178\n",
      "loop 95 0:00:10.848719\n",
      "loop 96 0:00:07.696433\n",
      "loop 97 0:00:06.344265\n",
      "loop 98 0:00:13.010651\n",
      "loop 99 0:00:08.955337\n",
      "loop 100 0:00:12.742729\n",
      "loop 101 0:00:10.340961\n",
      "loop 102 0:00:11.930945\n",
      "loop 103 0:00:10.280830\n",
      "loop 104 0:00:06.195483\n",
      "loop 105 0:00:08.388448\n",
      "loop 106 0:00:09.228110\n",
      "loop 107 0:00:08.586245\n",
      "loop 108 0:00:06.281412\n",
      "loop 109 0:00:06.477744\n",
      "loop 110 0:00:07.976499\n",
      "loop 111 0:00:06.278607\n",
      "loop 112 0:00:10.074416\n",
      "loop 113 0:00:12.205934\n",
      "loop 114 0:00:06.778008\n",
      "loop 115 0:00:06.375382\n",
      "loop 116 0:00:08.243392\n",
      "loop 117 0:00:06.450339\n",
      "loop 118 0:00:09.067697\n",
      "loop 119 0:00:10.519225\n",
      "loop 120 0:00:08.889310\n",
      "loop 121 0:00:12.206427\n",
      "loop 122 0:00:09.891738\n",
      "loop 123 0:00:05.530877\n",
      "loop 124 0:00:08.471976\n",
      "loop 125 0:00:12.104092\n",
      "loop 126 0:00:11.692196\n",
      "loop 127 0:00:07.728231\n",
      "loop 128 0:00:06.251299\n",
      "loop 129 0:00:05.466297\n",
      "loop 130 0:00:07.674755\n",
      "loop 131 0:00:12.571438\n",
      "loop 132 0:00:07.267505\n",
      "loop 133 0:00:12.962234\n",
      "loop 134 0:00:11.084370\n",
      "loop 135 0:00:07.775082\n",
      "loop 136 0:00:10.006777\n",
      "loop 137 0:00:10.247405\n",
      "loop 138 0:00:11.660505\n",
      "loop 139 0:00:09.186195\n",
      "loop 140 0:00:13.367683\n",
      "loop 141 0:00:11.657254\n",
      "loop 142 0:00:09.831325\n",
      "loop 143 0:00:06.299566\n",
      "loop 144 0:00:11.607415\n",
      "loop 145 0:00:09.524337\n",
      "loop 146 0:00:10.193492\n",
      "loop 147 0:00:11.060237\n",
      "loop 148 0:00:11.011590\n",
      "loop 149 0:00:10.550998\n",
      "loop 150 0:00:10.752070\n",
      "loop 151 0:00:08.557675\n",
      "loop 152 0:00:08.987536\n",
      "loop 153 0:00:08.804354\n",
      "loop 154 0:00:10.991912\n",
      "loop 155 0:00:12.147813\n",
      "loop 156 0:00:11.388938\n",
      "loop 157 0:00:08.129986\n",
      "loop 158 0:00:09.080804\n",
      "loop 159 0:00:10.260467\n",
      "loop 160 0:00:10.323091\n",
      "loop 161 0:00:08.796004\n",
      "loop 162 0:00:12.933191\n",
      "loop 163 0:00:06.159661\n",
      "loop 164 0:00:06.231116\n",
      "loop 165 0:00:06.749077\n",
      "loop 166 0:00:12.189583\n",
      "loop 167 0:00:09.778255\n",
      "loop 168 0:00:10.156542\n",
      "loop 169 0:00:13.010586\n",
      "loop 170 0:00:05.839984\n",
      "loop 171 0:00:06.234080\n",
      "loop 172 0:00:05.407809\n",
      "loop 173 0:00:08.683595\n",
      "loop 174 0:00:06.216645\n",
      "loop 175 0:00:12.311329\n",
      "loop 176 0:00:10.817291\n",
      "loop 177 0:00:06.281694\n",
      "loop 178 0:00:13.728202\n",
      "loop 179 0:00:06.594378\n",
      "loop 180 0:00:09.537806\n",
      "loop 181 0:00:12.314006\n",
      "loop 182 0:00:15.028978\n",
      "loop 183 0:00:14.459559\n",
      "loop 184 0:00:06.918918\n",
      "loop 185 0:00:06.598568\n",
      "loop 186 0:00:07.818650\n",
      "loop 187 0:00:12.880217\n",
      "loop 188 0:00:10.106002\n",
      "loop 189 0:00:13.668213\n",
      "loop 190 0:00:11.510972\n",
      "loop 191 0:00:08.312113\n",
      "loop 192 0:00:09.434755\n",
      "loop 193 0:00:11.901377\n",
      "loop 194 0:00:12.797299\n",
      "loop 195 0:00:06.473681\n",
      "loop 196 0:00:08.369683\n",
      "loop 197 0:00:06.500877\n",
      "loop 198 0:00:10.605701\n",
      "loop 199 0:00:09.776798\n",
      "loop 200 0:00:13.040879\n",
      "loop 201 0:00:14.086778\n",
      "loop 202 0:00:08.686937\n",
      "loop 203 0:00:12.920773\n",
      "loop 204 0:00:16.264186\n",
      "loop 205 0:00:10.383721\n",
      "loop 206 0:00:10.800939\n",
      "loop 207 0:00:11.836122\n",
      "loop 208 0:00:11.787508\n",
      "loop 209 0:00:14.550477\n",
      "loop 210 0:00:06.062057\n",
      "loop 211 0:00:09.111997\n",
      "loop 212 0:00:06.873409\n",
      "loop 213 0:00:12.710919\n",
      "loop 214 0:00:11.048864\n",
      "loop 215 0:00:18.417493\n",
      "loop 216 0:00:10.423401\n",
      "loop 217 0:00:10.391587\n",
      "loop 218 0:00:11.946432\n",
      "loop 219 0:00:08.099857\n",
      "loop 220 0:00:06.764455\n",
      "loop 221 0:00:11.703807\n",
      "loop 222 0:00:11.054874\n",
      "loop 223 0:00:10.292435\n",
      "loop 224 0:00:07.914745\n",
      "loop 225 0:00:08.234719\n",
      "loop 226 0:00:09.595497\n",
      "loop 227 0:00:11.322044\n",
      "loop 228 0:00:20.079330\n",
      "loop 229 0:00:17.422347\n",
      "loop 230 0:00:11.500313\n",
      "loop 231 0:00:12.162618\n",
      "loop 232 0:00:07.316078\n",
      "loop 233 0:00:11.596703\n",
      "loop 234 0:00:12.772325\n",
      "loop 235 0:00:19.852591\n",
      "loop 236 0:00:07.579373\n",
      "loop 237 0:00:08.988535\n",
      "loop 238 0:00:15.902169\n",
      "loop 239 0:00:15.508590\n",
      "loop 240 0:00:12.500887\n",
      "loop 241 0:00:07.002184\n",
      "loop 242 0:00:07.099809\n",
      "loop 243 0:00:14.100518\n",
      "loop 244 0:00:12.939182\n",
      "loop 245 0:00:12.712440\n",
      "loop 246 0:00:13.146728\n",
      "loop 247 0:00:09.861006\n",
      "loop 248 0:00:06.158114\n",
      "loop 249 0:00:06.751057\n",
      "loop 250 0:00:10.063140\n",
      "loop 251 0:00:11.687407\n",
      "loop 252 0:00:16.644836\n",
      "loop 253 0:00:14.454166\n",
      "loop 254 0:00:11.769291\n",
      "loop 255 0:00:08.956587\n",
      "loop 256 0:00:11.151412\n",
      "loop 257 0:00:13.820503\n",
      "loop 258 0:00:13.781731\n",
      "loop 259 0:00:14.622905\n",
      "loop 260 0:00:08.027447\n",
      "loop 261 0:00:10.176937\n",
      "loop 262 0:00:05.296869\n",
      "loop 263 0:00:09.547969\n",
      "loop 264 0:00:07.630827\n",
      "loop 265 0:00:15.854436\n",
      "loop 266 0:00:13.643002\n",
      "loop 267 0:00:11.606706\n",
      "loop 268 0:00:15.953632\n",
      "loop 269 0:00:11.003708\n",
      "loop 270 0:00:11.595072\n",
      "loop 271 0:00:05.970713\n",
      "loop 272 0:00:10.013509\n",
      "loop 273 0:00:06.669905\n",
      "loop 274 0:00:11.104398\n",
      "loop 275 0:00:06.312812\n",
      "loop 276 0:00:06.495063\n",
      "loop 277 0:00:10.696692\n",
      "loop 278 0:00:10.951726\n",
      "loop 279 0:00:11.917334\n",
      "loop 280 0:00:05.976437\n",
      "loop 281 0:00:14.213791\n",
      "loop 282 0:00:13.604614\n",
      "loop 283 0:00:20.974110\n",
      "loop 284 0:00:11.315180\n",
      "loop 285 0:00:08.606595\n",
      "loop 286 0:00:05.831403\n",
      "loop 287 0:00:10.165326\n",
      "loop 288 0:00:06.130897\n",
      "loop 289 0:00:09.603329\n",
      "loop 290 0:00:05.881444\n",
      "loop 291 0:00:05.257464\n",
      "loop 292 0:00:06.375630\n",
      "loop 293 0:00:11.763937\n",
      "loop 294 0:00:15.600787\n",
      "loop 295 0:00:09.896815\n",
      "loop 296 0:00:09.429094\n",
      "loop 297 0:00:12.297272\n",
      "loop 298 0:00:11.167974\n",
      "loop 299 0:00:07.499113\n",
      "loop 300 0:00:05.663200\n",
      "loop 301 0:00:09.900012\n",
      "loop 302 0:00:06.443103\n",
      "loop 303 0:00:11.752296\n",
      "loop 304 0:00:09.634162\n",
      "loop 305 0:00:11.209426\n",
      "loop 306 0:00:10.950417\n",
      "loop 307 0:00:11.230815\n",
      "loop 308 0:00:15.620265\n",
      "loop 309 0:00:13.450272\n",
      "loop 310 0:00:09.450397\n",
      "loop 311 0:00:10.530027\n",
      "loop 312 0:00:10.600555\n",
      "loop 313 0:00:10.956109\n",
      "loop 314 0:00:13.193237\n",
      "loop 315 0:00:07.553077\n",
      "loop 316 0:00:10.664972\n",
      "loop 317 0:00:08.396941\n",
      "loop 318 0:00:11.510557\n",
      "loop 319 0:00:14.901795\n",
      "loop 320 0:00:13.784851\n",
      "loop 321 0:00:07.256155\n",
      "loop 322 0:00:10.703794\n",
      "loop 323 0:00:08.142928\n",
      "loop 324 0:00:11.797802\n",
      "loop 325 0:00:06.030301\n",
      "loop 326 0:00:09.331360\n",
      "loop 327 0:00:06.422657\n",
      "loop 328 0:00:06.959104\n",
      "loop 329 0:00:06.908138\n",
      "loop 330 0:00:06.125563\n",
      "loop 331 0:00:07.573887\n",
      "loop 332 0:00:07.063466\n",
      "loop 333 0:00:07.276599\n",
      "loop 334 0:00:05.803050\n",
      "loop 335 0:00:10.206913\n",
      "loop 336 0:00:10.835506\n",
      "loop 337 0:00:06.980717\n",
      "loop 338 0:00:06.210819\n",
      "loop 339 0:00:11.397179\n",
      "loop 340 0:00:06.383256\n",
      "loop 341 0:00:09.970842\n",
      "loop 342 0:00:07.077766\n",
      "loop 343 0:00:10.927934\n",
      "loop 344 0:00:09.960513\n",
      "loop 345 0:00:09.789637\n",
      "loop 346 0:00:10.401896\n",
      "loop 347 0:00:11.485218\n",
      "loop 348 0:00:08.042774\n",
      "loop 349 0:00:10.257967\n",
      "loop 350 0:00:06.690800\n",
      "loop 351 0:00:12.021111\n",
      "loop 352 0:00:09.421073\n",
      "loop 353 0:00:12.792499\n",
      "loop 354 0:00:11.486817\n",
      "loop 355 0:00:06.431483\n",
      "loop 356 0:00:10.265235\n",
      "loop 357 0:00:06.025191\n",
      "loop 358 0:00:10.340980\n",
      "loop 359 0:00:07.324188\n",
      "loop 360 0:00:10.794744\n",
      "loop 361 0:00:06.680252\n",
      "loop 362 0:00:10.348999\n",
      "loop 363 0:00:11.249879\n",
      "loop 364 0:00:07.524679\n",
      "loop 365 0:00:07.919648\n",
      "loop 366 0:00:07.041696\n",
      "loop 367 0:00:09.665102\n",
      "loop 368 0:00:14.920072\n",
      "loop 369 0:00:11.354237\n",
      "loop 370 0:00:11.399070\n",
      "loop 371 0:00:09.513407\n",
      "loop 372 0:00:06.093051\n",
      "loop 373 0:00:11.157032\n",
      "loop 374 0:00:10.296915\n",
      "loop 375 0:00:10.598584\n",
      "loop 376 0:00:06.128138\n",
      "loop 377 0:00:06.386858\n",
      "loop 378 0:00:08.756185\n",
      "loop 379 0:00:06.891715\n",
      "loop 380 0:00:05.897935\n",
      "loop 381 0:00:11.241746\n",
      "loop 382 0:00:06.806763\n",
      "loop 383 0:00:06.502361\n",
      "loop 384 0:00:07.013233\n",
      "loop 385 0:00:07.188109\n",
      "loop 386 0:00:13.485544\n",
      "loop 387 0:00:06.106820\n",
      "loop 388 0:00:10.269647\n",
      "loop 389 0:00:05.990246\n",
      "loop 390 0:00:06.302541\n",
      "loop 391 0:00:12.345306\n",
      "loop 392 0:00:10.681322\n",
      "loop 393 0:00:10.623678\n",
      "loop 394 0:00:12.624559\n",
      "loop 395 0:00:12.597491\n",
      "loop 396 0:00:11.883777\n",
      "loop 397 0:00:06.586976\n",
      "loop 398 0:00:05.652342\n",
      "loop 399 0:00:10.039054\n",
      "loop 400 0:00:06.313142\n",
      "loop 401 0:00:09.513523\n",
      "loop 402 0:00:06.083479\n",
      "loop 403 0:00:10.000817\n",
      "loop 404 0:00:10.759741\n",
      "loop 405 0:00:10.387009\n",
      "loop 406 0:00:10.123999\n",
      "loop 407 0:00:05.648751\n",
      "loop 408 0:00:06.314763\n",
      "loop 409 0:00:06.825262\n",
      "loop 410 0:00:09.366671\n",
      "loop 411 0:00:14.376380\n",
      "loop 412 0:00:06.685661\n",
      "loop 413 0:00:12.009723\n",
      "loop 414 0:00:06.073273\n",
      "loop 415 0:00:09.837271\n",
      "loop 416 0:00:12.162291\n",
      "loop 417 0:00:11.849734\n",
      "loop 418 0:00:08.377642\n",
      "loop 419 0:00:09.587629\n",
      "loop 420 0:00:05.917630\n",
      "loop 421 0:00:08.681340\n",
      "loop 422 0:00:12.195597\n",
      "loop 423 0:00:10.249174\n",
      "loop 424 0:00:07.285508\n",
      "loop 425 0:00:11.283822\n",
      "loop 426 0:00:08.279371\n",
      "loop 427 0:00:11.735812\n",
      "loop 428 0:00:10.654602\n",
      "loop 429 0:00:09.512703\n",
      "loop 430 0:00:14.583342\n",
      "loop 431 0:00:05.669712\n",
      "loop 432 0:00:12.509321\n",
      "loop 433 0:00:05.077316\n",
      "loop 434 0:00:10.872650\n",
      "loop 435 0:00:09.530476\n",
      "loop 436 0:00:11.476272\n",
      "loop 437 0:00:13.190343\n",
      "loop 438 0:00:06.100248\n",
      "loop 439 0:00:08.436733\n",
      "loop 440 0:00:05.995975\n",
      "loop 441 0:00:08.545007\n",
      "loop 442 0:00:06.125645\n",
      "loop 443 0:00:08.817695\n",
      "loop 444 0:00:05.781279\n",
      "loop 445 0:00:07.398118\n",
      "loop 446 0:00:07.299014\n",
      "loop 447 0:00:10.299114\n",
      "loop 448 0:00:14.270296\n",
      "loop 449 0:00:14.870941\n",
      "loop 450 0:00:11.064878\n",
      "loop 451 0:00:09.983583\n",
      "loop 452 0:00:06.326835\n",
      "loop 453 0:00:11.214922\n",
      "loop 454 0:00:18.835206\n",
      "loop 455 0:00:13.229952\n",
      "loop 456 0:00:09.996446\n",
      "loop 457 0:00:04.988737\n",
      "loop 458 0:00:10.574250\n",
      "loop 459 0:00:04.401021\n",
      "loop 460 0:00:11.141375\n",
      "loop 461 0:00:09.040580\n",
      "loop 462 0:00:05.590475\n",
      "loop 463 0:00:05.210082\n",
      "loop 464 0:00:05.535295\n",
      "loop 465 0:00:05.924386\n",
      "loop 466 0:00:10.905298\n",
      "loop 467 0:00:11.509082\n",
      "loop 468 0:00:07.754678\n",
      "loop 469 0:00:05.658684\n",
      "loop 470 0:00:16.729184\n",
      "loop 471 0:00:10.004964\n",
      "loop 472 0:00:07.242352\n",
      "loop 473 0:00:10.663727\n",
      "loop 474 0:00:12.800273\n",
      "loop 475 0:00:13.365126\n",
      "loop 476 0:00:11.186528\n",
      "loop 477 0:00:11.960475\n",
      "loop 478 0:00:06.263331\n",
      "loop 479 0:00:07.339146\n",
      "loop 480 0:00:05.815958\n",
      "loop 481 0:00:05.476470\n",
      "loop 482 0:00:07.594357\n",
      "loop 483 0:00:12.642678\n",
      "loop 484 0:00:11.471037\n",
      "loop 485 0:00:09.616029\n",
      "loop 486 0:00:10.717409\n",
      "loop 487 0:00:07.531240\n",
      "loop 488 0:00:11.798479\n",
      "loop 489 0:00:09.665283\n",
      "loop 490 0:00:05.492959\n",
      "loop 491 0:00:06.357269\n",
      "loop 492 0:00:09.466832\n",
      "loop 493 0:00:12.452302\n",
      "loop 494 0:00:07.989475\n",
      "loop 495 0:00:10.110299\n",
      "loop 496 0:00:13.730191\n",
      "loop 497 0:00:09.954560\n",
      "loop 498 0:00:10.392691\n",
      "loop 499 0:00:13.397360\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,500):\n",
    "    start = datetime.datetime.now()\n",
    "    X_copy=X_np\n",
    "    Xj_np=np.zeros((1,400))\n",
    "    Xj_np[0,:]=X_copy[i,:]\n",
    "    X_j_np=np.delete(X_copy,[i],axis=0)\n",
    "    X_j_np.shape\n",
    "    #############################\n",
    "    Xj1=Xj_np.astype(\"float32\")\n",
    "    Xj2=torch.from_numpy(Xj1).to(device)\n",
    "    Xj=torch.t(Xj2)\n",
    "    X_j1=X_j_np.astype(\"float32\")\n",
    "    X_j2=torch.from_numpy(X_j1).to(device)\n",
    "    X_j=torch.t(X_j2)\n",
    "    one=torch.ones(400,1).to(device)\n",
    "    X_j_sum=torch.cat((one,X_j),1)\n",
    "    #####################\n",
    "    beta1=SCAD(X_j_sum,Xj,0.11,400,500)\n",
    "    supp=int(sup(beta1))+1\n",
    "    #########################\n",
    "    XX=X_j_sum.cpu().detach().numpy()\n",
    "    YY=Xj.cpu().detach().numpy()\n",
    "    Y=np.squeeze(YY)\n",
    "    ##############################\n",
    "    reg = OrthogonalMatchingPursuit(supp).fit(XX, Y)\n",
    "    p=reg.coef_\n",
    "    ###############################\n",
    "    Z=Y-XX.dot(p)\n",
    "    r=Z.T.dot(Z)/(n-supp)\n",
    "    beta=beta1.cpu().detach().numpy()\n",
    "    w=beta/r\n",
    "    w[0]=1/r\n",
    "    read=np.zeros((500,1))\n",
    "    for k in range(0,i):\n",
    "        read[k]=w[k+1]\n",
    "    read[i]=w[0]\n",
    "    for k in range(i+1,500):\n",
    "        read[k]=w[k]\n",
    "    omega[:,i]=read[:,0]\n",
    "    end = datetime.datetime.now()\n",
    "    print(\"loop\",i,end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"math287model1new\",omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt=np.load(\"math287model1new.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee=rt\n",
    "for i in range(0,500):\n",
    "    for j in range(i,500):\n",
    "        if (np.abs(ee[i,j])<=np.abs(ee[j,i])):\n",
    "            ee[j,i]=ee[i,j]\n",
    "        else:\n",
    "            ee[i,j]=ee[j,i]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=ee-sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: 9.504053712383124 Operator； 0.8364146453163639 1,inf: 1.6029051155317575\n"
     ]
    }
   ],
   "source": [
    "print(\"F:\",np.linalg.norm(dd,ord = 'fro'),\"Operator；\",np.linalg.norm(dd,ord = 2),\"1,inf:\",np.linalg.norm(dd,ord = np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TP(KK):\n",
    "    summ=0\n",
    "    for i in range(2,498):\n",
    "        for j in range(i-2,i+3):\n",
    "            if(KK[i,j]!=0):\n",
    "                summ=summ+1\n",
    "                KK[i,j]=0\n",
    "    u=(summ+14)/(5*500-6)\n",
    "    return(u)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9390537289494787"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TN(KK):\n",
    "    for i in range(2,498):\n",
    "        for j in range(i-2,i+3):\n",
    "                KK[i,j]=0\n",
    "    summ=0             \n",
    "    for i in range(0,500):\n",
    "        for j in range(0,500):\n",
    "            if(KK[i,j]!=0):\n",
    "                summ=summ+1\n",
    "    u=(summ-14)/(500*500-2494)\n",
    "    return(1-u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9754591807875365"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
